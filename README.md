# Large-Language-Model-Yi
Prompt Engineering refers to the development and optimization of prompts that interact with LLM to guide it to produce the desired results without the need for model updates. Prompt Engineering can help researchers improve the ability of large language models to handle complex tasks, such as question answering and arithmetic reasoning, or enhance the performance and effectiveness of generative AI models in specific task scenarios.

There are four important elements in the writing of prompts:

1: Instruction: Clearly specify the specific task or instruction that the language model is expected to perform.

2: Context: Providing external information or additional context to guide language models to better understand and respond.

3: Input data: including user input content or questions, as the basis for generating output for the model.

4: Output indication: Specify the expected output type or format.

I conducted in-depth research on the Yi series models while being exposed to different large language models like Qwen, Chatglm, Bluelm and so on. I have gained a deep understanding of prompt engineering and how to rewrite prompts
